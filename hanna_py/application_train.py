# -*- coding: utf-8 -*-
"""application-train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DsvkGLGE_tWtjVm6pPc6mSMeOI3W3FC4
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import os
import re
from scipy import stats
from scipy.stats import norm, skew
import matplotlib
import matplotlib.pyplot as plt # for plotting
# %matplotlib inline
import seaborn as sns # for making plots with seaborn
color = sns.color_palette()
import warnings
warnings.filterwarnings('ignore') # Suppress warnings

# importing the datasets into Pandas dataframes
data_test = pd.read_csv('../input/home-credit-default-risk/application_test.csv')
df_test = data_test.copy()
data_train = pd.read_csv('../input/home-credit-default-risk/application_train.csv')
df_train = data_train.copy()
df_pre = pd.read_csv('../input/home-credit-default-risk/previous_application.csv')

pd.set_option('display.max_rows', None)
# pd.options.display.max_rows = 60
pd.set_option('display.max_columns', None)

df_train.shape

df_train.info()

df_train.describe()

df_train.describe(include="all")

df_train.head()

df_train.columns.values

def type_features(data):
    categorical_features = data.select_dtypes(include = ["object"]).columns
    numerical_features = data.select_dtypes(exclude = ["object"]).columns
    print( "categorical_features :",categorical_features)
    print('-----'*20)
    print("numerical_features:",numerical_features)

type_features(df_train)

df_train.hist(bins=50, figsize=(50, 45))
plt.show()

df_train.boxplot(figsize=(50, 45))
plt.show()

def missingdata(data):
    total = data.isnull().sum().sort_values(ascending = False)
    percent = (data.isnull().sum()/data.isnull().count()*100).sort_values(ascending = False)
    ms=pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])
    ms= ms[ms["Percent"] > 0]
    f,ax =plt.subplots(figsize=(15,10))
    plt.xticks(rotation='90')
    fig=sns.barplot(ms.index, ms["Percent"],color="green",alpha=0.8)
    plt.xlabel('Features', fontsize=15)
    plt.ylabel('Percent of missing values', fontsize=15)
    plt.title('Percent missing data by feature', fontsize=15)
    #ms= ms[ms["Percent"] > 0]
    return ms

missingdata(df_train)

target = df_train["TARGET"]

target.value_counts()

f,ax=plt.subplots(1,2,figsize=(12,6))
df_train.TARGET.value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)
ax[0].set_title('Distribution of target variable')
ax[0].set_ylabel('')
sns.countplot('TARGET',data=df_train,ax=ax[1])
ax[1].set_title('Count of Repayer VS defulter')
plt.show()

plt.ylabel('Instances')
plt.xlabel('TARGET value')
plt.title('Target Variable Distribution (Training Dataset)')
sns.countplot(x='TARGET', data=df_train);

contract_type = df_train["NAME_CONTRACT_TYPE"]

contract_type.value_counts()

plt.ylabel('Instances')
plt.xlabel('contract_type value')
plt.title('contract_type Variable Distribution (Training Dataset)')
sns.countplot(x='NAME_CONTRACT_TYPE', data=df_train);

def plot_stats(feature,label_rotation=False,horizontal_layout=True):
    temp = df_train[feature].value_counts()
    df1 = pd.DataFrame({feature: temp.index,'Number of contracts': temp.values})

    # Calculate the percentage of target=1 per category value
    cat_perc = df_train[[feature, 'TARGET']].groupby([feature],as_index=False).mean()
    cat_perc.sort_values(by='TARGET', ascending=False, inplace=True)
    
    if(horizontal_layout):
        fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6))
    else:
        fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(12,14))
    sns.set_color_codes("pastel")
    s = sns.barplot(ax=ax1, x = feature, y="Number of contracts",data=df1)
    if(label_rotation):
        s.set_xticklabels(s.get_xticklabels(),rotation=90)
    
    s = sns.barplot(ax=ax2, x = feature, y='TARGET', order=cat_perc[feature], data=cat_perc)
    if(label_rotation):
        s.set_xticklabels(s.get_xticklabels(),rotation=90)
    plt.ylabel('Percent of target with value 1 [%]', fontsize=10)
    plt.tick_params(axis='both', which='major', labelsize=10)

    plt.show();

plot_stats('NAME_CONTRACT_TYPE')

"""Cash loans 대출 수가 전체 대출수의 약 95% 
Revolving loans 가 전체 대출수의 약 5% 
"""

plot_stats('CODE_GENDER')

"""* 대출하는 고객은 여성이 남성보다 약 2배이상
* 채무불이행은 남성이 더 높음 (남성10%/여성7%)
"""

plot_stats('FLAG_OWN_CAR')
plot_stats('FLAG_OWN_REALTY')

"""* 차를 소유하지 않은 사람이 소유한 사람보다 약 2배 많음
* 집을 소유한 사람이 소유하지 않은 사람보다 약 2배 많음
* 채무불이행 비율은 비슷함
"""

plot_stats('NAME_FAMILY_STATUS',True, True)

"""* 대부분의 고객이 결혼함"""

plot_stats('CNT_CHILDREN')

"""* 대출받는 고객의 대부분이 자녀가 없음. (자녀1명을 둔 고객은 자녀 없는 고객의 약 1/4)"""

plot_stats('CNT_FAM_MEMBERS',True)

"""* 가족인원이 2명인 경우 고객이 가장 많음"""

plot_stats('NAME_INCOME_TYPE',False,False)

"""* 대출 신청자는 근로소득이 대부분 그리고 상업관계자
* 채무불이행은 출산휴가자가 약 40%, 그리고 실업자가 약 37%
"""

plot_stats('OCCUPATION_TYPE',True, False)

"""* 대부분의 대출은 노동자 그리고 영업직원이 다음
* IT 직원이 가장 낮음
* 채무불이행은 저숙련 노동자가 가장 많고 운전,이발사,경비원, 노무자, 등이 다음
"""

plot_stats('ORGANIZATION_TYPE',True, False)

plot_stats('NAME_EDUCATION_TYPE',True)

"""* 중등교육받은 고객이 대다수, 학위 있는 사람은 적음."""

plot_stats('NAME_HOUSING_TYPE',True)

"""* 고객의 대부분이 주택/아파트에 거주"""

def plot_distribution(feature,color):
    plt.figure(figsize=(10,6))
    plt.title("Distribution of %s" % feature)
    sns.distplot(df_train[feature].dropna(),color=color, kde=True,bins=100)
    plt.show()

# Plot distribution of multiple features, with TARGET = 1/0 on the same graph
def plot_distribution_comp(var,nrow=2):
    
    i = 0
    t1 = df_train.loc[df_train['TARGET'] != 0]
    t0 = df_train.loc[df_train['TARGET'] == 0]

    sns.set_style('whitegrid')
    plt.figure()
    fig, ax = plt.subplots(nrow,2,figsize=(12,6*nrow))

    for feature in var:
        i += 1
        plt.subplot(nrow,2,i)
        sns.kdeplot(t1[feature], bw=0.5,label="TARGET = 1")
        sns.kdeplot(t0[feature], bw=0.5,label="TARGET = 0")
        plt.ylabel('Density plot', fontsize=12)
        plt.xlabel(feature, fontsize=12)
        locs, labels = plt.xticks()
        plt.tick_params(axis='both', which='major', labelsize=12)
    plt.show();

plot_distribution('AMT_INCOME_TOTAL','green')

plot_distribution('AMT_CREDIT','blue') # 대출총액

plot_distribution('AMT_ANNUITY','tomato') #매달 내야하는 돈(이자 포함)

plot_distribution('AMT_GOODS_PRICE','brown') # 대출받아서 사려고 한 상품 총액

plot_distribution('DAYS_BIRTH','blue')

"""* 나이 분포 약 20~68세"""

plot_distribution('DAYS_EMPLOYED','red') #신청일 기준 현재 직장에서 일한 일 수

plot_distribution('DAYS_REGISTRATION','green') # 고객이 등록서류를 변경한 일 수, 신청일 기준

#고객이 대출을 신청한 동안에 신분증 문서를 변경한 일수, 신청일 기준
plot_distribution('DAYS_ID_PUBLISH','blue')

# Comparison of interval values with TARGET = 1 and TARGET = 0
var = ['AMT_ANNUITY','AMT_GOODS_PRICE','DAYS_EMPLOYED', 'DAYS_REGISTRATION','DAYS_BIRTH','DAYS_ID_PUBLISH']
plot_distribution_comp(var,nrow=3)

# 클라이언트의 영구 주소가 연락처 주소와 일치하지 않는 경우 플래그 지정
# (1=다름, 0=동일, 지역 수준)
plot_stats('REG_REGION_NOT_LIVE_REGION')
# 고객 영구 주소와 직장 주소가 일치하는지
plot_stats('REG_REGION_NOT_WORK_REGION')

"""* 일반적으로 거주하거나 일하는 곳 주소 등록
* 다른 곳에 등록할 경우 채무불이행 경우가 더 많음
"""

numerical_features = df_train.select_dtypes(exclude = ["object"]).columns

numerical_features

plt.boxplot(df_train['CNT_CHILDREN'])

plt.boxplot(df_train['AMT_INCOME_TOTAL'])

plt.boxplot(df_train['AMT_CREDIT'])

plt.boxplot(df_train['REGION_POPULATION_RELATIVE'])

"""* **이상치 제거**"""

def get_outlier(df=None, column=None, weight=1.5):
  # target 값과 상관관계가 높은 열을 우선적으로 진행
  quantile_25 = np.percentile(df_train[column].values, 25)
  quantile_75 = np.percentile(df_train[column].values, 75)

  IQR = quantile_75 - quantile_25
  IQR_weight = IQR*weight
  
  lowest = quantile_25 - IQR_weight
  highest = quantile_75 + IQR_weight
  
  outlier_idx = df_train[column][ (df_train[column] < lowest) | (df_train[column] > highest) ].index
  return outlier_idx

# 함수 사용해서 이상치 값 삭제
outlier_idx = get_outlier(df=df_train, column='CNT_CHILDREN', weight=7.0)
df_train.drop(outlier_idx, axis=0, inplace=True)

plt.boxplot(df_train['CNT_CHILDREN'])

df_train.shape

# importing the datasets into Pandas dataframes
data_test = pd.read_csv('../input/home-credit-default-risk/application_test.csv')
df_test = data_test.copy()
data_train = pd.read_csv('../input/home-credit-default-risk/application_train.csv')
df_train = data_train.copy()

